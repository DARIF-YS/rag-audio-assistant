## üó£Ô∏è RAG Audio Assistant

Ce projet illustre la cr√©ation d‚Äôun chatbot RAG (Retrieval-Augmented Generation) pour questions-r√©ponses audio.
L‚Äôobjectif est de permettre √† l‚Äôutilisateur de t√©l√©verser un fichier audio ou vid√©o, d‚Äôextraire et indexer son contenu, puis de poser des questions sur ce contenu avec des r√©ponses contextuelles g√©n√©r√©es par un mod√®le de langage.

### a. Key Features
- **Audio/Video transcription** using OpenAI Whisper  
- **Semantic search & retrieval** with Chroma and Hugging Face embeddings  
- **Context-aware answers** generated by Google Gemini  
- **Interactive web interface** built with Streamlit  

### b. Project Workflow

Here‚Äôs a visual representation of the workflow:

![Workflow](images/workflow.png)  
*Figure: App workflow from media upload to Q&A.*

Steps in detail:
1. **Upload media**: Users upload an audio or video file.  
2. **Transcription**: The app transcribes the media content using Whisper.  
3. **Indexing**: Transcribed text is split into chunks and stored in a vector database (Chroma) using embeddings.  
4. **Question & Answer**: Users can ask questions about the content, and answers are generated by Google Gemini based on the indexed transcription.  

### c. Demo

See the app in action:

![Demo](images/demo.png)  
*Figure: Demo of the app interface with transcription and Q&A functionality.*

By the end of this project, you will have a fully functional system that combines **speech recognition**, **vector search**, and **LLM-based reasoning** to efficiently understand and query audio content.

### d. Setup & Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/DARIF-YS/audio-qa-app.git
   cd audio-qa-app

2. Install dependencies:
    ```bash
    pip install -r requirements.txt

3. Create a .env file in the project root and add your Google API key:
    
    GOOGLE_API_KEY=YOUR_GOOGLE_API_KEY

4. Run the app:
    ```bash
    streamlit run app.py
__

*Developed by Yassine DARIF - 2025*
